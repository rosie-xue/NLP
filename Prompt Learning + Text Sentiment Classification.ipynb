{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rosie-xue/NLP/blob/main/Prompt%20Learning%20%2B%20Text%20Sentiment%20Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GP1twQCl9tOy"
      },
      "source": [
        "# 提示学习（Prompt Learning）\n",
        "\n",
        "## NLP的训练范式  \n",
        "\n",
        "<img src=\"./NLP训练范式.png\" alt=\"NLP训练范式\" width=\"1200\">\n",
        "\n",
        "目前学术界一般将NLP任务的发展分为四个阶段，即NLP四范式：\n",
        "\n",
        "1. **第一范式：基于传统机器学习模型的范式**\n",
        "   - 例如：tf-idf 特征+朴素贝叶斯等机器算法。\n",
        "\n",
        "2. **第二范式：基于深度学习模型的范式**\n",
        "   - 例如：word2vec 特征 + LSTM 等深度学习算法。\n",
        "   - 相比于第一范式，模型准确度有所提高，特征工程的工作也有所减少。\n",
        "\n",
        "3. **第三范式：基于预训练模型 + finetuning的范式**\n",
        "   - 例如：BERT + finetuning 的NLP任务。\n",
        "   - 相比于第二范式，模型准确度显著提高，但是模型也随之变得更大，但小数据集就可训练出好模型。\n",
        "\n",
        "4. **第四范式：基于预训练模型 + Prompt + 预测的范式**\n",
        "   - 例如：BERT + Prompt 的范式。\n",
        "   - 相比于第三范式，模型训练所需的训练数据显著减少。\n",
        "\n",
        "<img src=\"./prompt示例.png\" alt=\"prompt示例\" width=\"1200\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrukRQqb9tO3"
      },
      "source": [
        "<img src=\"./下游任务微调.png\" alt=\"下游任务微调\" width=\"500\">\n",
        "\n",
        "\n",
        "第三范式是想要预训练模型更好的应用在下游任务，需要利用下游数据对模型参数微调；首先，模型在预训练的时候，采用的训练形式：自回归、自编码，这与下游任务形式存在极大的 gap，不能完全发挥预训练模型本身的能力\n",
        "\n",
        "必然导致：较多的数据来适应新的任务形式——>少样本学习能力差、容易过拟合。\n",
        "\n",
        "上下游任务形式存在gap其次，现在的预训练模型参数量越来越大，为了一个特定的任务去 finetuning 一个模型，然后部署于线上业务，也会造成部署资源的极大浪费。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c0yIWcd9tO3"
      },
      "source": [
        "## 为什么提示学习？\n",
        "<img src=\"./性能对比.png\" alt=\"性能对比\" width=\"500\">\n",
        "\n",
        "预训练模型中存在大量知识；预训练模型本身具有少样本学习能力。GPT-3 提出的 In-Context Learning，也有效证明了在 Zero-shot、Few-shot场景下，模型不需要任何参数，就能达到不错的效果，特别是近期很火的GPT3.5系列中的 ChatGPT。\n",
        "\n",
        "### Prompt Learning 的本质\n",
        "- **核心理念**：将所有下游任务统一成预训练任务。\n",
        "- **方法**：以特定的模板，将下游任务的数据转成自然语言形式，充分挖掘预训练模型本身的能力。\n",
        "- **关键步骤**：\n",
        "  1. 设计预训练语言模型的任务。\n",
        "  2. 设计输入模板样式（Prompt Engineering）。\n",
        "  3. 设计label 样式及模型的输出映射到label 的方式（Answer Engineering）。\n",
        "\n",
        "### Prompt Learning 的形式\n",
        "- **示例：电影评论情感分类**\n",
        "  - 原始输入：特效非常酷炫，我很喜欢。\n",
        "  - Prompt 输入：\n",
        "    1. 提示模板1: 特效非常酷炫，我很喜欢。这是一部[MASK]电影。\n",
        "    2. 提示模板2: 特效非常酷炫，我很喜欢。这部电影很[MASK]。\n",
        "  - **作用**：将训练数据转成自然语言的形式，并在合适的位置 MASK，以激发预训练模型的能力。\n",
        "\n",
        "### 模板框架类别映射/Verbalizer\n",
        "- **目标**：选择合适的预测词，并将这些词对应到不同的类别。\n",
        "- **优势**：类别映射通过构建提示学习样本，只需要少量数据的 Prompt Tuning，就可以实现很好的效果，具有较强的零样本/少样本学习能力。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usElddnn9tO4"
      },
      "source": [
        "## 硬模板-PET（Pattern Exploiting Training）\n",
        "\n",
        "<img src=\"./PET.png\" alt=\"PET\" width=\"500\">\n",
        "\n",
        "PET 是一种较为经典的提示学习方法。它将问题建模成一个完形填空问题，然后优化最终的输出词。虽然 PET 也是在优化整个模型的参数，但是相比于传统的 Finetuning 方法，对数据量需求更少。\n",
        "\n",
        "### 建模方式\n",
        "- 传统模型只需对 P(l|x) 建模（l 是 label）。\n",
        "- 加入 Prompt P 及标签映射（verbalizer），问题更新为：\\[P(l|x, P, M)\\]（M 表示模型，s 为某个 prompt 下生成对应 word 的 logits）。\n",
        "- 通过 softmax 得到概率。\n",
        "- 加入 MLM loss 进行联合训练。\n",
        "\n",
        "### 具体做法\n",
        "- 在少量监督数据上，给每个 Prompt 训练一个模型。\n",
        "- 对于无监督数据，集成同一样本的多个 prompt 预测结果，采用平均或加权（根据准确率分配权重）方式，归一化得到概率分布，作为无监督数据的 soft label。\n",
        "- 在得到的 soft label 上 finetune 最终模型。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sdrGg5q9tO4"
      },
      "source": [
        "## 软模板- P Tuning（V1/V2）\n",
        "\n",
        "![P-tuning-v2](./P-tuning-v2.png)\n",
        "\n",
        "P Tuning 是一种不再依赖硬模板设计或搜索的方法。它在输入端直接插入若干可被优化的 Pseudo Prompt Tokens，自动化地寻找连续空间中的知识模板。\n",
        "\n",
        "### 特点\n",
        "- **不依赖人工设计**：完全自动化的过程。\n",
        "- **参数优化**：优化的参数极少，避免了过拟合。也可全量微调，退化成传统的 finetuning。\n",
        "\n",
        "### 工作原理\n",
        "- 传统离散 prompt 直接将模板 T 的每个 token 映射为对应的 embedding。\n",
        "- P-Tuning 将模板 T 中的 Pi（Pseudo Prompt）映射为一个可训练的参数 hi。\n",
        "- 优化关键：将自然语言的 hard prompt 替换为可训练的 soft prompt。\n",
        "- 使用双向 LSTM 对模板 T 中的 pseudo token 序列进行表征。\n",
        "- 引入少量自然语言提示的锚字符（Anchor）提升效率，如“capital”。\n",
        "\n",
        "### 具体做法\n",
        "- **初始化模板**：例如 \"The capital of [X] is [mask]\"。\n",
        "- **替换输入**：例如 [X] 处替换为输入 “Britain”，即预测 Britain 的首都。\n",
        "- **挑选模板中的一个或多个 token 作为 soft prompt**。\n",
        "- **处理 soft prompt**：将所有 soft prompt 送入 LSTM，获得每个 soft prompt 的隐状态向量 h。\n",
        "- **模型运用**：将初始模板送入 BERT 的 Embedding Layer，所有 soft prompt 的 token embedding 用 h 代替，然后预测 mask。\n",
        "\n",
        "### 核心结论\n",
        "- 在基于全量数据的大模型中，仅微调 prompt 相关的参数，可媲美 fine-tuning 的表现。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FK0DMAYB9tO4"
      },
      "source": [
        "# 思维链（Chain of Thought）\n",
        "\n",
        "![cot](./cot.png)\n",
        "\n",
        "## 背景知识\n",
        "\n",
        "思维链是一种自然语言处理（NLP）技术，旨在通过模拟人类解决问题的逻辑思维过程来提升大规模语言模型的性能。这种方法特别适用于复杂问题解决任务，如数学问题、逻辑推理等。\n",
        "\n",
        "### 基本原理\n",
        "思维链方法基于一个假设：如果模型能够像人类一样“思考”并解释其解题过程，那么它解决问题的能力会更强。在实践中，这通常意味着向模型提供一个问题，并引导它生成一系列逻辑步骤，而不是直接输出最终答案。\n",
        "\n",
        "### 发展历史\n",
        "思维链的概念源于人类解决问题时通常不直接跳到答案，而是经历一系列思考步骤的观察。最近，随着大规模语言模型如GPT-3的发展，研究者开始探索如何将这种“思维过程”集成到模型中，以提高其解决复杂问题的能力。\n",
        "\n",
        "## 应用案例\n",
        "\n",
        "### 数学问题解答\n",
        "在解决数学问题时，思维链可以用来展示逐步的计算过程。例如，对于一个简单的加法问题，模型会首先识别它需要添加两个数，然后逐步计算总和，最后给出答案。\n",
        "\n",
        "### 逻辑推理\n",
        "在逻辑推理任务中，如解释现象或推断因果关系，思维链可以帮助模型明确每个逻辑步骤，从而提供更加准确和可解释的答案。\n",
        "\n",
        "### 语言理解\n",
        "在更复杂的语言理解任务中，如阅读理解或对话理解，思维链帮助模型在给出答案之前，先阐述其理解和推理过程，这有助于提高答案的准确性和可靠性。\n",
        "\n",
        "## 结论\n",
        "\n",
        "思维链作为一种提高大规模语言模型解决问题能力的技术，不仅增强了模型的准确性，还提供了一种可解释AI的途径。通过模拟人类思考的步骤，思维链使得模型的输出不仅是简单的答案，而是一个完整、逻辑连贯的解决方案。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBrWc_mw9tO5",
        "outputId": "48477a06-2d5b-423c-86bf-c0335cec5fd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.19.1 dill-0.3.8 multiprocess-0.70.16 xxhash-3.4.1\n",
            "Collecting zhipuai\n",
            "  Downloading zhipuai-2.1.0.20240521-py3-none-any.whl (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.1/68.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools>=4.2.2 in /usr/local/lib/python3.10/dist-packages (from zhipuai) (5.3.3)\n",
            "Collecting httpx>=0.23.0 (from zhipuai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3.0,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from zhipuai) (2.7.1)\n",
            "Collecting pyjwt<2.9.0,>=2.8.0 (from zhipuai)\n",
            "  Downloading PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->zhipuai) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->zhipuai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.23.0->zhipuai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->zhipuai) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->zhipuai) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.23.0->zhipuai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0,>=1.9.0->zhipuai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0,>=1.9.0->zhipuai) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0,>=1.9.0->zhipuai) (4.11.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.23.0->zhipuai) (1.2.1)\n",
            "Installing collected packages: pyjwt, h11, httpcore, httpx, zhipuai\n",
            "  Attempting uninstall: pyjwt\n",
            "    Found existing installation: PyJWT 2.3.0\n",
            "    Uninstalling PyJWT-2.3.0:\n",
            "      Successfully uninstalled PyJWT-2.3.0\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 pyjwt-2.8.0 zhipuai-2.1.0.20240521\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install zhipuai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suSi0kOl9tO6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "from torch.utils.data import DataLoader\n",
        "from datasets import load_dataset\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtouC-J79tO6"
      },
      "outputs": [],
      "source": [
        "#加载训练集，从训练集和验证集得到例子\n",
        "dataset = load_dataset(\"imdb\")\n",
        "\n",
        "random_train_indices = random.sample(range(len(dataset[\"train\"])), 1000)\n",
        "random_test_indices = random.sample(range(len(dataset[\"test\"])), 1000)\n",
        "\n",
        "test_dataset = dataset[\"test\"].select(random_test_indices)\n",
        "train_dataset = dataset[\"train\"].select(random_train_indices)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbR93w2c9tO6"
      },
      "source": [
        "### 基于 BERT 提示工程的 IDMB 文本情感分类"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siGiwcfy9tO7"
      },
      "outputs": [],
      "source": [
        "def evaluate_bert_model(model, tokenizer, test_loader, device):#把mask问题放在前面\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    references = []\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_loader):\n",
        "            batch_texts = batch['text']\n",
        "            # TODO: 构建prompt模板（如何构建提示模板？）\n",
        "            masked_texts = [\"This movie was [MASK]. \"+text for text in batch_texts]\n",
        "            inputs = tokenizer(masked_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "            pred = outputs.logits\n",
        "            mask_token_index = torch.where(inputs.input_ids == tokenizer.mask_token_id)[1]\n",
        "\n",
        "            # TODO: 构建标签映射词表（如何更好地构建？ good bad的概率都很低？ 引入更多标签词汇terrible nice）\n",
        "            positive_id = tokenizer.convert_tokens_to_ids(\"good\")\n",
        "            negative_id = tokenizer.convert_tokens_to_ids(\"bad\")\n",
        "\n",
        "            # 分析每个文本的情感\n",
        "            for j in range(pred.shape[0]):\n",
        "                mask_pred = pred[j, mask_token_index[j], :]\n",
        "                positive_prob = mask_pred[positive_id].item()\n",
        "                negative_prob = mask_pred[negative_id].item()\n",
        "                sentiment = 1 if positive_prob > negative_prob else 0  #如果积极概率更大，就判断为正向\n",
        "                predictions.append(sentiment)\n",
        "            references.extend(batch[\"label\"].tolist())\n",
        "\n",
        "    return accuracy_score(references, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hh2C0TP29tO7"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
        "\n",
        "acc = evaluate_bert_model(model, tokenizer, test_loader, device)\n",
        "print(\"Accuracy: \", acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vn2F16KB9tO7"
      },
      "source": [
        "### 基于生成式大语言模型（API）提示工程的 IDMB 文本情感分类"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-44v0qqg9tO8"
      },
      "outputs": [],
      "source": [
        "# 如需调用不同模型 API，修改以下代码\n",
        "\n",
        "from zhipuai import ZhipuAI\n",
        "\n",
        "client = ZhipuAI(api_key=\"635bc426d639ff8105708d498f2ae68e.NDH5DUAeOuPlRsBT\") # 填写您自己的APIKey\n",
        "def get_api_response(text):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"glm-3-turbo\",  # 填写需要调用的模型名称\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": text},\n",
        "        ],\n",
        "    )\n",
        "    return response.choices[0].message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMVxUHme9tO8"
      },
      "outputs": [],
      "source": [
        "def evaluate_llm_model(test_dataset, train_dataset, topk=0):\n",
        "    predictions = []\n",
        "    references = test_dataset[\"label\"]\n",
        "    template = \"\\nWhat is the emotional preference of this movie review? (positive/negative)\"\n",
        "\n",
        "    exmaples = ''\n",
        "    samples = random.sample(range(len(train_dataset)), topk)\n",
        "    for i in samples:\n",
        "        if train_dataset[i][\"label\"] == 1:\n",
        "            label = \"positive\"\n",
        "        else:\n",
        "            label = \"negative\"\n",
        "        exmaples += train_dataset[i][\"text\"] + template + '\\n' + label + '\\n'\n",
        "\n",
        "    for text in tqdm(test_dataset[\"text\"]):\n",
        "        prompt = text + template\n",
        "        response = str(get_api_response(prompt)).lower()\n",
        "        sentiment = 1 if \"positive\" in response.lower() else 0\n",
        "        predictions.append(sentiment)\n",
        "    return accuracy_score(references, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "8szhaU8n9tO8",
        "outputId": "8bfed0ac-170b-4bf8-c6d2-6886fdec960d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 4/1000 [00:09<38:52,  2.34s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-b615e3f3246a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_llm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-e6971e73aa99>\u001b[0m in \u001b[0;36mevaluate_llm_model\u001b[0;34m(test_dataset, train_dataset, topk)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_api_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0msentiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"positive\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentiment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-dd6179a6bb93>\u001b[0m in \u001b[0;36mget_api_response\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZhipuAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"635bc426d639ff8105708d498f2ae68e.NDH5DUAeOuPlRsBT\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 填写您自己的APIKey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_api_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     response = client.chat.completions.create(\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"glm-3-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# 填写需要调用的模型名称\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         messages=[\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/zhipuai/api_resource/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, model, request_id, do_sample, stream, temperature, top_p, max_tokens, seed, messages, stop, sensitive_word_check, tools, tool_choice, meta, extra_headers, extra_body, timeout)\u001b[0m\n\u001b[1;32m     70\u001b[0m                     \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_prefix_image_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             body={\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/zhipuai/core/_http_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_type, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m    806\u001b[0m         )\n\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/zhipuai/core/_http_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_type, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0mstream_cls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mType\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mStreamResponse\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m     ) -> ResponseT | StreamResponse:\n\u001b[0;32m--> 494\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    495\u001b[0m             \u001b[0mcast_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/zhipuai/core/_http_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_type, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"auth\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustom_auth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             response = self._client.send(\n\u001b[0m\u001b[1;32m    520\u001b[0m                 \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m                 \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stream_response_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0mauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_request_auth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         response = self._send_handling_auth(\n\u001b[0m\u001b[1;32m    915\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m                 response = self._send_handling_redirects(\n\u001b[0m\u001b[1;32m    943\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m                     \u001b[0mfollow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_redirects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    977\u001b[0m                 \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_single_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"response\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1015\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSyncByteStream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    231\u001b[0m         )\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_connections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;31m# Return the response. Note that in this case we still have to manage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                     \u001b[0;31m# Send the request on the assigned connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                     response = connection.handle_request(\n\u001b[0m\u001b[1;32m    197\u001b[0m                         \u001b[0mpool_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/connection.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNetworkStream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"response_closed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;31m# Sending the request...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    111\u001b[0m                     \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtrailing_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                 ) = self._receive_response_headers(**kwargs)\n\u001b[0m\u001b[1;32m    114\u001b[0m                 trace.return_value = (\n\u001b[1;32m    115\u001b[0m                     \u001b[0mhttp_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEED_DATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                 data = self._network_stream.read(\n\u001b[0m\u001b[1;32m    225\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_NUM_BYTES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_backends/sync.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1286\u001b[0m                     \u001b[0;34m\"non-zero flags not allowed in calls to recv() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m                     self.__class__)\n\u001b[0;32m-> 1288\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1159\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "acc = evaluate_llm_model(test_dataset, train_dataset, topk=0)\n",
        "print(\"Accuracy: \", acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oz4ePm669tO8"
      },
      "source": [
        "# QUESTIONS：\n",
        "\n",
        "1. **Prompt Learning 与传统微调的区别是什么？**\n",
        "- Prompt Learning可以在少量数据甚至无数据的情况下工作。只需调整提示或少量参数，计算成本低。可以通过修改提示快速适应不同任务，不需要重新训练模型。\n",
        "\n",
        "2. **在设计有效的提示（prompts）时应考虑哪些因素？**\n",
        "- 任务匹配度：明确任务类型和目标，分类、生成、填空等。例如，分类任务需要明确指示模型进行分类操作。\n",
        "- 语言和格式：使用自然且符合人类语言习惯的提示。确保提示格式在整个数据集中保持一致，以避免混淆模型。\n",
        "- 提示内容：提示应该包含足够的信息，使模型能够准确地理解并执行任务，但也不要过于冗长。使用与任务高度相关的关键词，避免模糊和泛化的提示，尽量具体和明确。\n",
        "- 提示位置：将提示放在输入文本的开头，有助于模型快速理解任务。或在输入文本中嵌入提示，使其更自然地融入上下文。\n",
        "- 实验和优化：可以设计多个不同的提示进行实验，观察哪种提示效果最好。根据实验结果，逐步优化和调整提示的内容和结构。\n",
        "- 模型特性：不同大小和架构的模型对提示的响应可能不同，需针对特定模型设计提示。还要了解模型在预训练过程中接触的数据类型和风格。\n",
        "\n",
        "3. **在实现基于 BERT 提示工程的情感分类任务时，选择哪些候选标签可能更有效，为什么？**\n",
        "- 简单的正面、负面标签可能不够精准和细致，所以在某些情感分析任务中，可能需要更细化的情感类别。例如：高兴、愤怒、悲伤、惊讶、中性。\n",
        "- 还可以根据具体的情感分析任务，选择与任务背景相关的标签。例如，在分析电影评论时：喜欢、不喜欢，在分析产品评价时：满意、不满意\n",
        "- 此外，考虑到上下文和使用场景，选择能够捕捉到更细微情感变化的标签。例如，在社交媒体分析中：赞、踩、笑、怒\n",
        "\n",
        "4. **对于提示工程，Zero-shot 和 Few-shot 的区别是什么？Few-shot如何选择恰当的例子？**\n",
        "\n",
        "**区别**：\n",
        "1. **Zero-shot（零样本）**：面对新任务，在没有训练样本的情况下，根据其已有的知识和训练数据来尝试完成该任务。例如，当使用ChatGPT时，如果不给任何示例，直接让它回答问题，ChatGPT会根据你的问题按照它自己训练的数据进行回复。\n",
        "2. **Few-shot（少样本）**：给模型提供少量特定任务的训练样本，以帮助模型更好地理解任务。如：在对ChatGPT提问时给出1个或少量示例，ChatGPT会参考这些示例来解答问题。这些示例可以帮助模型更准确地理解你的意图和需求。\n",
        "**Few-shot如何选择恰当的例子**：\n",
        "\n",
        "1. **相关性**：选择的示例应与要执行的任务高度相关,并能清晰地展示任务的输入和期望的输出。\n",
        "2. **多样性**：示例应具有多样性，以覆盖任务的各种可能情况。这有助于模型更全面地理解任务，并提高其泛化能力。\n",
        "3. **简洁性**：示例应尽可能简洁明了，避免引入不必要的复杂性。\n",
        "4. **质量**：示例的质量至关重要。应确保示例是准确的、无误的，并且能够清晰地传达任务的意图和要求。"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}